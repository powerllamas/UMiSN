%%%%%%%%%%%%%%%%%% Część II %%%%%%%%%%%%%%%%%

\section{Generowanie reguł decyzyjnych}

\subsection{Metoda pośrednia generowania reguł (\emph{C4.5rules})}
\begin{itemize}
\item \textbf{Wygeneruj reguły dla zbioru \emph{GOLF} za~pomocą programu \emph{C4.5 for Windows}.}

\input{figures/part2/task1/rules}
	\\Wyniki pokazane są na Rys.~\ref{p2t1-rules}.

\item \textbf{Porównaj wygenerowane reguły z~wyjściowym drzewem decyzyjnym. Czy reguły odzwierciedlają precyzyjnie drzewo?}

\input{figures/part2/task1/trees}

	\\Wyjściowe drzewo zostało przedstawione na Rys.~\ref{p2t1-tree}. Drzewo to nie może być odtworzone przy użyciu samych tylko uzyskanych reguł (Rys.~\ref{p2t1-rules}). Jest tak, ponieważ nie pokrywają one wszystkich możliwych ścieżek od~korzenia do liścia -- brakuje reguły dla \texttt{outlook = sunny AND humidity <= 75}. Ponieważ jednak w~wyniku zawarta jest również klasa domyślna, w~tym wypadku \texttt{Play}, możemy ją wykorzystać jako liść dla ścieżek w~drzewie odpowiadającym brakującym regułom. W~ten sposób, w~tym konkretnym przypadku, możliwe jest zrekonstruowanie drzewa. Stąd reguły odzwierciedlają drzewo w~sposób precyzyjny.
\end{itemize}

\subsection{Porównanie klasyfikowania za pomocą drzew decyzyjnych i~reguł decyzyjnych (\emph{C4.5rules})}
\begin{itemize}
\item \textbf{Przeprowadź testy \emph{10-fold CV} na wybranych zbiorach dla drzew i~reguł.}

\input{figures/part2/task2/golf-trees-cv}
\input{figures/part2/task2/golf-rules-cv}
\input{figures/part2/task2/vote-trees-cv}
\input{figures/part2/task2/vote-rules-cv}
	\\Wyniki uzyskane z~programu \emph{C4.5 for windows} zostały przedstawione następująco: dla zbioru \emph{golf} w~Tab.~\ref{p2t2-golf-trees-cv} oraz Tab.~\ref{p2t2-golf-rules-cv}, dla zbioru \emph{vote} w~Tab.~\ref{p2t2-vote-trees-cv} oraz Tab.~\ref{p2t2-vote-rules-cv}.

\item \textbf{Porównaj wyniki pod kątem trafności klasyfikowania na zbiorze testującym oraz rozmiaru opisu.}
	
	\input{figures/part2/task2/compare-errors}
	\\Na Rys.~\ref{p2t2-compare-errors} przedstawiono zależność między trafnością klasyfikowania a~typem reprezentacji (drzewa, reguły). Dla wszystkich zbiorów danych z~wyjątkiem \emph{golf} reprezentacja regułowa daje lepszą klasyfikację niż drzewa. (Drobne różnice między drzewem po pruningu a~regułami dla zbioru \emph{vote} pomijamy.)
	\\Odmienną zależność dla zbioru \emph{golf} możemy tłumaczyć małą liczbą przypadków uczących w~tym zbiorze -- zaledwie 14~przykładów -- przez co zbiory testowe zawierają 1-2~przypadków testowych. W~tej sytuacji pojedynczy błąd ma istotny wpływ na końcową jakość klasyfikacji.
	
	\input{figures/part2/task2/compare-sizes}
	\\Na Rys.~\ref{p2t2-compare-sizes} dokonano porównania rozmiarów różnych reprezentacji wiedzy dla kilku wybranych zbiorów danych. Jako jednostkę przyjęto w~przypadku drzew pojedynczy liść, zaś w~przypadku reguł pojedynczą regułę. Widać znaczną redukcję rozmiaru przy przejściu od drzew bez pruningu przez drzewa z~pruningiem do reguł.
	
\item \textbf{Przeprowadzając kilka eksperymentów uczenia i~testowania przeanalizuj wpływ parametrów \emph{Confidence Level} i~\emph{Redundancy Factor} na~otrzymywany zbiór reguł.}

	\input{figures/part2/task2/vote-confidence-level}
	\\Parametr \emph{Confidence Level} steruje liczbą i~rozmiarem reguł. Dla zbioru \emph{vote} zależność między wartością tego parametru a~rozmiarem zbioru reguł i~liczbą błędów przy klasyfikacji przedstawia tabela \ref{p2t2-vote-confidence-level}. Jak widać, zwiększenie wartości parametru prowadzi do zwiększenia rozmiaru zbioru reguł. Wprawdzie oznacza to polepszenie klasyfikacji dla zbioru uczącego, jednak (w~przypadku zbioru \emph{vote}) nie zauważono wpływu na jakość klasyfikacji dla zbioru testowego.

	\input{figures/part2/task2/vote-redundancy-factor}
	\\Parametr \emph{Redundancy Factor} steruje wyborem atrybutów do~reguł. Dla zbioru \emph{vote} zależność między wartością parametru a~rozmiarem zbioru reguł i~liczbą błędów przy klasyfikacji przedstawiona jest w~tabeli \ref{p2t2-vote-redundancy-factor}. Im mniejsza wartość parametru, tym mniej atrybutów zostanie wybranych do pojedynczej reguły decyzyjnej, co wpływa bezpośrednio na rozmiar samego zbioru reguł. W~zbiorze \emph{vote} zaobserwowano polepszenie klasyfikacji dla małych wartości \emph{Redundancy Factor}.

	\\Podsumowując, sterując tymi parametrami można uniknąć przeuczenia systemu, efekty jednak zależeć będą od~konkretnego zbioru przykładów uczących.
\end{itemize}


	\subsection{Generowanie reguł z~użyciem algorytmu \emph{LEM}}

\begin{itemize}
\item Wygeneruj reguły dla zbioru \emph{HPAP.ISF}.
\item Przyjrzyj się regułom możliwym; opisz je i~,,wydedukuj'', skąd się wzięły.
\end{itemize}

\subsection{Porównanie reguł generowanych za~pomocą algorytmu \emph{LEM} i~\emph{C4.5}}

\begin{itemize}
\item Wygeneruj reguły przy użyciu obu podejść dla zbiorów: \emph{HPAP}, \emph{VOTE} i~\emph{MONK}.
\item Przyjrzyj się niezależnie regułom pewnym i~możliwym (\emph{LEM}).
\end{itemize}

%Dla chętnych:
%\subsection{Przeprowadź eksperyment generowania i~testowania reguł LEM w~ramach cross validation}